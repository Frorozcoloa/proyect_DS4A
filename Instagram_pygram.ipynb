{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Scraper usando pygram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerias\n",
    "from pygram import PyGram\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pygram = PyGram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionan los usuarios a los cuales se les van a buscar los posts y se establece la ruta de la carpeta de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usernames\n",
    "usernames = ['offcorss', 'epk', 'babyfreshoficial', 'politokids']\n",
    "# folder path\n",
    "folder_path = r'C:\\Users\\DavidCordoba\\Google Drive\\Estudio\\Cursos\\2020. DS4A\\Project\\Instagram_Scraper\\proyect_DS4A-master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publicaciones de usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para extraer las publicaciones del usuario seleccionados\n",
    "\n",
    "Se crea una función para extraer la información de un solo usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_df(username, limit = 100):\n",
    "    \"\"\" Extrae los posts del usuario y los convierta en un pandas dataframe.\n",
    "    RETORNA:\n",
    "    pandas.DataFrame: pandas.DataFrame con la información de los posts solicitados del usuario seleccionado.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Devuelve una lista de diccionarios\n",
    "    posts = list(pygram.get_posts(username, limit = limit))\n",
    "    print(len(posts), ' posts collected from ', username)\n",
    "\n",
    "    # Convierte la lista de diccionarios en pd dataframe\n",
    "    posts_df = pd.DataFrame(posts)\n",
    "    # Adiciona en columna date\n",
    "    posts_df['date'] = posts_df.timestamp.apply(lambda x: datetime.fromtimestamp(x))\n",
    "\n",
    "    return posts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para extraer las publicaciones todos los usuarios\n",
    "\n",
    "Se crea otra función para extraer la información de múltiples usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_from_usernames(usernames, limit = 100):\n",
    "    \"\"\" Crea una dataframe con un número especifico de posts de todos los usernames ingresados.\n",
    "    RETORNA:\n",
    "    pandas.DataFrame: pandas.DataFrame con la información de los posts solicitados de los usuarios seleccionados.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se crea una lista de dataframes con los dataframes de cada user\n",
    "    posts_df = []\n",
    "    for user in usernames:\n",
    "        posts_df.append(get_posts_df(user, limit = limit))\n",
    "        \n",
    "    # Se concatenan los dataframes en uno solo\n",
    "    posts_df = pd.concat(posts_df)\n",
    "    \n",
    "    return posts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualización o creación de base de datos de publicaciones\n",
    "\n",
    "Se busca (en caso de que exista), una base de datos con información de publiaciones anteriores y se actualiza con la nueva información encontrada (si la publicación ya estaba en la base de datos, se actualizan sus parámetros tales cómo comentarios, likes, vistas, etc y si la publicación no estaba en la base de datos entonces se añade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  posts collected from  offcorss\n",
      "10  posts collected from  epk\n",
      "10  posts collected from  babyfreshoficial\n",
      "10  posts collected from  politokids\n"
     ]
    }
   ],
   "source": [
    "# Se llaman las funciones para recolectar la última información de posts de los usuarios\n",
    "posts_df = get_posts_from_usernames(usernames, limit = 10)\n",
    "\n",
    "try:\n",
    "    # Se lee la base de datos\n",
    "    posts_database = pd.read_csv(Path(folder_path)/'posts_database.csv')\n",
    "    # Se actualiza la base de datos\n",
    "    posts_database = pd.concat([posts_database, posts_df])\n",
    "    posts_database['id'] = posts_database['id'].astype('int64')\n",
    "    posts_database.drop_duplicates(subset = 'id', keep = 'last', inplace = True)\n",
    "    # Se guarda la base de datos\n",
    "    posts_database.to_csv(Path(folder_path)/'posts_database.csv', index = False)\n",
    "    \n",
    "except:\n",
    "    # Se crea y guarda la base de datos\n",
    "    posts_df.to_csv(Path(folder_path)/'posts_database.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20060, 12)\n",
      "20060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>author</th>\n",
       "      <th>video_views_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.006000e+04</td>\n",
       "      <td>20060.000000</td>\n",
       "      <td>2.006000e+04</td>\n",
       "      <td>20060.000000</td>\n",
       "      <td>2.006000e+04</td>\n",
       "      <td>2275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.521979e+18</td>\n",
       "      <td>7.972084</td>\n",
       "      <td>1.495654e+09</td>\n",
       "      <td>299.516052</td>\n",
       "      <td>2.287647e+08</td>\n",
       "      <td>3576.322637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.342097e+17</td>\n",
       "      <td>28.146271</td>\n",
       "      <td>6.368277e+07</td>\n",
       "      <td>405.083033</td>\n",
       "      <td>2.025129e+07</td>\n",
       "      <td>6839.484191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.578409e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.344957e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.080347e+08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.103811e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.445805e+09</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>2.142773e+08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.564603e+18</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500735e+09</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>2.221308e+08</td>\n",
       "      <td>1262.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.946751e+18</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.546291e+09</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>2.605503e+08</td>\n",
       "      <td>5077.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.416338e+18</td>\n",
       "      <td>1578.000000</td>\n",
       "      <td>1.602270e+09</td>\n",
       "      <td>11051.000000</td>\n",
       "      <td>2.605503e+08</td>\n",
       "      <td>117171.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  comments_count     timestamp   likes_count        author  \\\n",
       "count  2.006000e+04    20060.000000  2.006000e+04  20060.000000  2.006000e+04   \n",
       "mean   1.521979e+18        7.972084  1.495654e+09    299.516052  2.287647e+08   \n",
       "std    5.342097e+17       28.146271  6.368277e+07    405.083033  2.025129e+07   \n",
       "min    2.578409e+17        0.000000  1.344957e+09      0.000000  2.080347e+08   \n",
       "25%    1.103811e+18        0.000000  1.445805e+09     85.000000  2.142773e+08   \n",
       "50%    1.564603e+18        3.000000  1.500735e+09    182.000000  2.221308e+08   \n",
       "75%    1.946751e+18        8.000000  1.546291e+09    360.000000  2.605503e+08   \n",
       "max    2.416338e+18     1578.000000  1.602270e+09  11051.000000  2.605503e+08   \n",
       "\n",
       "       video_views_count  \n",
       "count        2275.000000  \n",
       "mean         3576.322637  \n",
       "std          6839.484191  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%          1262.000000  \n",
       "75%          5077.000000  \n",
       "max        117171.000000  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esto solo nos sirve para dar una idea de la data, no realiza ninguna alteración a la data\n",
    "posts_database = pd.read_csv(Path(folder_path)/'posts_database.csv')\n",
    "\n",
    "print(posts_database.shape)\n",
    "print(len(posts_database.reset_index()['id'].unique()))\n",
    "posts_database.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios de publicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para extraer los comentarios de una publicación y actualizar la base de datos\n",
    "\n",
    "Esta función tiene cómo objetivo extraer los comentarios de una sola publicación y con esta información actualizar la base de datos en csv, esto debido a que la forma de extraer los comentarios tiende a fallar con facilidad entonces para no realizar solicitudes erroneas y evitar la perdida de la información. La función busca en la base de datos de comentarios que publicación todavia no se ha scrapeado nunca y trata de realizar el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_df(posts_database, comments_database, limit = 10000):\n",
    "    \"\"\" Actualiza el dataframe de comentarios con los comentarios de una de las publicaciónes que no se haya scrapeado.\n",
    "    RETORNA:\n",
    "    pandas.DataFrame: pandas.DataFrame de los comentarios actualizado y el estado de la transacción (Exitosa o fallida).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se busca un id que no tenga comentarios\n",
    "    post_id = random.choice(list(comments_database[pd.isna(comments_database['id'])]['post_id']))\n",
    "    # Se encuentra el post de ese id en df\n",
    "    post_df = posts_database[posts_database['id'] == post_id]\n",
    "    # Se pasa el post df a una estructura de diccionario\n",
    "    post_dict = post_df.to_dict(orient='index')\n",
    "    post_dict = list(post_dict.values())[0]\n",
    "    \n",
    "    try:\n",
    "          \n",
    "        # Se buscan los comentarios de ese post y devuelve una lista de diccionarios\n",
    "        comments = list(pygram.get_comments(post_dict, limit = limit))\n",
    "        print(len(comments), ' comments collected from the post with ID: ', post_id)\n",
    "    \n",
    "        # Convierte la lista de diccionarios en pd dataframe\n",
    "        comments_df = pd.DataFrame(comments)\n",
    "        # Adiciona en columna date\n",
    "        comments_df['date'] = comments_df.timestamp.apply(lambda x: datetime.fromtimestamp(x))\n",
    "        # Impongo esquema\n",
    "        comments_dtypes = {'id': 'object',\n",
    "                           'text': 'object',\n",
    "                           'timestamp': 'float64',\n",
    "                           'author': 'object',\n",
    "                           'post_id': 'object',\n",
    "                           'date': 'datetime64[ns]'}\n",
    "        for key, value in comments_dtypes.items():\n",
    "            comments_df[key] = comments_df[key].astype(value)\n",
    "            \n",
    "        # Elimino la fila que tiene el post_id scrapeado\n",
    "        comments_database.drop(comments_database.index[comments_database['post_id'] == post_id].tolist(), inplace = True)\n",
    "        # Agrego las filas con los comentarios scrapeados y Concateno ambos dataframes\n",
    "        comments_database = pd.concat([comments_database, comments_df])\n",
    "        # Se guarda la base de datos\n",
    "        comments_database.to_csv(Path(folder_path)/'comments_database.csv', index = False)  \n",
    "        success = True\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print('There was an error when running the pygram library, the limit was probably exceeded')\n",
    "        success = False\n",
    "        \n",
    "    return comments_database, success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para actualizar la base de datos de los comentarios con los post ids nuevos\n",
    "\n",
    "En esta función se utiliza la base de datos de publicaciones para mirar que nuevas publicaciones hay que la base de datos de comentarios no esté teniendo en cuenta y actualiza el dataframe de comentarios únicamente con el post id de las publicaciones que deben ser posteriormente scrapeadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_post_ids_in_comments_database():\n",
    "    \"\"\" Actualiza el dataframe de comentarios los post ids nuevos que tenga la base de datos de publicaciones.\n",
    "    RETORNA:\n",
    "    pandas.DataFrame: pandas.DataFrame de los comentarios actualizado con los nuevos post ids.\n",
    "    \"\"\"\n",
    "\n",
    "    # Se lee la base de datos de los posts y se impone el esquema\n",
    "    posts_database = pd.read_csv(Path(folder_path)/'posts_database.csv')\n",
    "    posts_dtypes = {'id': 'object',\n",
    "                    'shortcode': 'object',\n",
    "                    'comments_disabled': 'bool',\n",
    "                    'comments_count': 'int64',\n",
    "                    'timestamp': 'float64',\n",
    "                    'display_url': 'object',\n",
    "                    'likes_count': 'int64',\n",
    "                    'author': 'object',\n",
    "                    'is_video': 'bool',\n",
    "                    'caption': 'object',\n",
    "                    'video_views_count': 'float64',\n",
    "                    'date': 'datetime64[ns]'}\n",
    "    for key, value in posts_dtypes.items():\n",
    "        posts_database[key] = posts_database[key].astype(value)\n",
    "\n",
    "    # Se trata de leer la base de datos de los comentarios y sino se buscan los comentarios de una publicacion cualquiera para crear la estructura\n",
    "    try:\n",
    "\n",
    "        # Se lee la base de datos de los comentarios y se impone el formato\n",
    "        comments_database = pd.read_csv(Path(folder_path)/'comments_database.csv')\n",
    "        comments_dtypes = {'id': 'object',\n",
    "                           'text': 'object',\n",
    "                           'timestamp': 'float64',\n",
    "                           'author': 'object',\n",
    "                           'post_id': 'object',\n",
    "                           'date': 'datetime64[ns]'}\n",
    "        for key, value in comments_dtypes.items():\n",
    "            comments_database[key] = comments_database[key].astype(value)\n",
    "\n",
    "        # Adiciono todos los id de posts que no esten en el comments_df\n",
    "        # Creo un df con todos los posts id que no estan en comments_database\n",
    "        comments_df = pd.DataFrame(columns = ['id', 'text', 'timestamp', 'author', 'post_id', 'date'])\n",
    "        comments_df['post_id'] = [post_id for post_id in list(posts_database[posts_database['comments_count'] > 0]['id']) if post_id not in list(comments_database['post_id'])]\n",
    "        # Se impone el formato\n",
    "        for key, value in comments_dtypes.items():\n",
    "            comments_df[key] = comments_df[key].astype(value)\n",
    "        # Concateno ambos dataframes\n",
    "        comments_database = pd.concat([comments_database, comments_df])\n",
    "        # Se guarda la base de datos\n",
    "        comments_database.to_csv(Path(folder_path)/'comments_database.csv', index = False)  \n",
    "\n",
    "    except:\n",
    "\n",
    "        # Creo un df vacio con las columnas respectivas y le impongo el esquema\n",
    "        comments_database = pd.DataFrame(columns = ['id', 'text', 'timestamp', 'author', 'post_id', 'date'])\n",
    "        # Adiciono todos los id de posts que no esten en el comments_df\n",
    "        comments_database['post_id'] = list(posts_database[posts_database['comments_count'] > 0]['id'])\n",
    "        # Impongo el formato del esquema\n",
    "        comments_dtypes = {'id': 'object',\n",
    "                           'text': 'object',\n",
    "                           'timestamp': 'float64',\n",
    "                           'author': 'object',\n",
    "                           'post_id': 'object',\n",
    "                           'date': 'datetime64[ns]'}\n",
    "        for key, value in comments_dtypes.items():\n",
    "            comments_database[key] = comments_database[key].astype(value)\n",
    "        # Se crea y guarda la base de datos\n",
    "        comments_database.to_csv(Path(folder_path)/'comments_database.csv', index = False)\n",
    "\n",
    "#     print(comments_database.info(), '\\n')\n",
    "#     try:\n",
    "#         print(comments_df.info(), '\\n')\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "    return posts_database, comments_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para completar la base de datos de comentarios con todos los comentarios faltantes\n",
    "\n",
    "Esta función explora la base de datos de comentarios y busca todos los post ids que no tengan comentarios y recorre todos estos buscando sus respectivos comentarios en Instragram hasta que la libreria de pygram falla y entonces se detiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_comments_database(limit_posts = -1, limit_comments = 10000, wait = 5):\n",
    "    \"\"\" Trata de completar todos los comentarios faltantes de la base de datos de comentarios haciendo uso de los post ids.\n",
    "    RETORNA:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Actualizo las bases de datos con los post ids\n",
    "    posts_database, comments_database = update_post_ids_in_comments_database()\n",
    "    # Calculo el máximo e posts a iterar, si es -1 entonces todos los faltantes y si es diferente a -1 entonces ese número.\n",
    "    if limit_posts == -1:\n",
    "        limit_posts = len(comments_database[pd.isna(comments_database['id'])]['post_id'])\n",
    "    \n",
    "    # Voy a través de todos los post id que no tienen comentarios y trato de completarlos\n",
    "    for i in range(limit_posts):\n",
    "        \n",
    "        time.sleep(wait)\n",
    "        # Actualizo un comentario de la base de datos\n",
    "        comments_database, success = get_comments_df(posts_database, comments_database, limit = limit_comments)\n",
    "        if not success:\n",
    "            break\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para actualizar los comentarios de las publicaciones más recientes\n",
    "\n",
    "Esta función sirve para buscar las publicaciones más recientes, hacer scraping de sus comentarios y actualizar los nuevos comentarios en la base de datos de comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_comments_database(limit_posts = 100, limit_comments = 10000, wait = 5):\n",
    "    \"\"\" Trata de actualizar los comentarios de las publicaciones más recientes.\n",
    "    RETORNA:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    posts_database, comments_database = update_post_ids_in_comments_database()\n",
    "\n",
    "    # Se buscan los 100 posts más actuales\n",
    "    post_ids = list(posts_database.sort_values(by = ['timestamp'], ascending = False)['id'])[0:limit_posts] #revisar codigo\n",
    "    # Se encuentran los posts de esos ids\n",
    "    posts_df = posts_database[posts_database['id'].isin(post_ids)]\n",
    "    # Se pasa el post df a una estructura de diccionario\n",
    "    posts_dict = posts_df.to_dict(orient = 'index')\n",
    "    posts_dict = list(posts_dict.values())\n",
    "\n",
    "    for post_dict in posts_dict:\n",
    "\n",
    "        time.sleep(wait)\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Se buscan los comentarios de ese post y devuelve una lista de diccionarios\n",
    "            comments = list(pygram.get_comments(post_dict, limit = limit_comments))\n",
    "            print(len(comments), ' comments collected from the post with ID: ', post_dict['id'])\n",
    "\n",
    "            # Convierte la lista de diccionarios en pd dataframe\n",
    "            comments_df = pd.DataFrame(comments)\n",
    "            # Adiciona en columna date\n",
    "            comments_df['date'] = comments_df.timestamp.apply(lambda x: datetime.fromtimestamp(x))\n",
    "            # Impongo esquema\n",
    "            comments_dtypes = {'id': 'object',\n",
    "                               'text': 'object',\n",
    "                               'timestamp': 'float64',\n",
    "                               'author': 'object',\n",
    "                               'post_id': 'object',\n",
    "                               'date': 'datetime64[ns]'}\n",
    "            for key, value in comments_dtypes.items():\n",
    "                comments_df[key] = comments_df[key].astype(value)\n",
    "\n",
    "            # Agrego las filas con los comentarios scrapeados y Concateno ambos dataframes y elimino los comentarios repetidos\n",
    "            comments_database = pd.concat([comments_database, comments_df])\n",
    "            comments_database['id'] = comments_database['id'].astype('float64')\n",
    "            comments_database.drop_duplicates(subset = 'id', keep = 'last', inplace = True)\n",
    "            comments_database['id'] = comments_database['id'].astype('object')\n",
    "            # Se guarda la base de datos\n",
    "            comments_database.to_csv(Path(folder_path)/'comments_database.csv', index = False)  \n",
    "            success = True\n",
    "\n",
    "        except:\n",
    "\n",
    "            print('There was an error when running the pygram library, the limit was probably exceeded')\n",
    "            success = False\n",
    "            break\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completado de los comentarios de las publicaciones\n",
    "\n",
    "Se utiliza la función de completado de comentarios para llenar la base de datos de comentarios. Si se desea intentar completar toda la base de datos utilziar el parámetro limit_posts = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  comments collected from the post with ID:  1659836777407961135\n",
      "1  comments collected from the post with ID:  386855397782788346\n",
      "7  comments collected from the post with ID:  1827005512294654315\n",
      "4  comments collected from the post with ID:  1293106371088184997\n",
      "4  comments collected from the post with ID:  2022664947184893292\n",
      "6  comments collected from the post with ID:  2386742890319051782\n",
      "7  comments collected from the post with ID:  2078004015858105722\n",
      "3  comments collected from the post with ID:  2127245003429043782\n",
      "1  comments collected from the post with ID:  1883552776207331272\n",
      "3  comments collected from the post with ID:  2022685204482523337\n",
      "1  comments collected from the post with ID:  1016142495494705953\n",
      "11  comments collected from the post with ID:  1718474990297775788\n",
      "0  comments collected from the post with ID:  1303718315532886380\n",
      "There was an error when running the pygram library, the limit was probably exceeded\n"
     ]
    }
   ],
   "source": [
    "fill_comments_database(limit_posts = -1, limit_comments = 10000, wait = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualización de base de datos de comentarios\n",
    "\n",
    "Se utiliza la función de actualización de comentarios para buscar las publicaciones más recientes y actualizar sus comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  comments collected from the post with ID:  2416323704633079000\n",
      "7  comments collected from the post with ID:  2416337884922791971\n"
     ]
    }
   ],
   "source": [
    "update_comments_database(limit_posts = 2, limit_comments = 10000, wait = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
